---
title: "Quarto_Learning_Playground"
format: html
editor: visual
---

# (15/04) Manipuler des données spatiales avec sf et faire des facettes avec ggplot2 

On va créer un petit dataset de 6 points fictifs dans deux "sources", avec leurs coordonnées.

```{r}
library(sf)
library(ggplot2)
library(dplyr)
```

## 1 : Créer des données spatiales simples

### Créer un petit jeu de données

```{r}
df <- data.frame(
  id = 1:6,
  lon = c(2.35, 2.36, 2.37, -1.68, -1.67, -1.69),  # Paris et Rennes
  lat = c(48.85, 48.86, 48.87, 48.11, 48.12, 48.13),
  source = c("atlas", "atlas", "atlas", "steli", "steli", "steli")
)
```

### Transformer en objet spatial

```{r}
df_sf <- st_as_sf(df, coords = c("lon", "lat"), crs = 4326)  # EPSG 4326 = WGS84
```

Maintenant `df_sf` est un objet spatial avec des points géographiques

## 2 : Visualiser les points avec ggplot2

```{r}
ggplot() +
  geom_sf(data = df_sf, aes(color = source), size = 3) +
  theme_minimal()
```

J'obtiens une carte simple avec des points colorés selon la source

## 3 : Ajouter des facettes

Je sépare les données par source, avec une facette par "atlas" et une par "steli".

```{r}
ggplot() +
  geom_sf(data = df_sf, aes(color = source), size = 3) +
  facet_wrap(vars(source)) +
  theme_minimal()
```

Résultat : deux sous-cartes côte à côte, une pour chaque source

## 4 : Changer de projection

Je transforme les données vers une projection en mètres.

```{r}
df_sf_proj <- st_transform(df_sf, 3035)

# Même graphe, mais avec projection européenne
ggplot() +
  geom_sf(data = df_sf_proj, aes(color = source), size = 3) +
  facet_wrap(vars(source)) +
  theme_minimal()
```

## 5 : Ajouter une carte en fond et simuler une grille + compter le nb de pts / case

### Ajouter une carte de fond (France)

```{r}
library(rnaturalearth)
library(rnaturalearthdata)

# Récupérer la carte de la France
fr <- ne_countries(scale = 50, country = "France", returnclass = "sf")

# La projeter comme nos données (EPSG:3035)
fr_3035 <- st_transform(fr, 3035)
df_sf_proj <- st_transform(df_sf, 3035)

# Carte avec fond
ggplot() +
  geom_sf(data = fr_3035, fill = "white", color = "black") +
  geom_sf(data = df_sf_proj, aes(color = source), size = 2) +
  facet_wrap(vars(source)) +
  coord_sf(
    xlim = c(bbox$xmin, bbox$xmax),
    ylim = c(bbox$ymin, bbox$ymax),
    expand = FALSE
  ) +
  theme_minimal()
```

### Simuler une grille spatiale

On crée une grille carrée et on compte combien de points tombent dans chaque case.

```{r}
# Créer une grille régulière qui couvre la France
grid <- st_make_grid(fr_3035, cellsize = 100000, square = TRUE)  # 100 km
grid <- st_sf(id = 1:length(grid), geometry = grid)

# Croiser la grille avec les points (spatial join)
df_joined <- st_join(df_sf_proj, grid, left = FALSE)  # left = FALSE = ne garde que les points qui tombent dans la grille

# Compter les observations par case et par source
nobs_grid <- df_joined |>
  group_by(id = id.y, source) |>
  summarize(n = n(), .groups = "drop")

# Joindre avec la grille
grid_counts <- left_join(grid, st_drop_geometry(nobs_grid), by = "id")
```

### Affichage : Carte des occurrences par cellule (avec ggplot2)

```{r}
ggplot() +
  geom_sf(data = fr_3035, fill = "white", color = "grey80") +  # fond de carte France
  geom_sf(data = grid_counts, aes(fill = n), color = NA) +     # cellules colorées
  scale_fill_viridis_c(
    trans = "log", 
    breaks = c(1, 10, 100, 1000, 10000),
    na.value = "lightgrey",
    name = "Occurrences"
  ) +
  coord_sf(xlim = c(bbox$xmin, bbox$xmax), ylim = c(bbox$ymin, bbox$ymax)) +
  theme_void(base_size = 14) +
  theme(
    legend.position = "left",
    legend.key.height = unit(1.2, "cm")
  )
```

Carte pas très intéressante avec ce jeu de données mais bon voilà.

# (16/04, 17/04) Se familiariser à data.table sur les données odonates 

## Charger les données avec data.table

```{r}
library(data.table)
library(here)

# Définir le chemin du fichier
read_folder <- here("data/03_grid")
# Charger les données dans un data.table
dat <- readRDS(file.path(read_folder, "french_odonate_data.rds"))
dat <- as.data.table(dat)
# Structure des données 
str(dat)
```

## Premiers exemples pratiques

```{r}
# nb tot d'obs
dat[ , .N]  # .N = nombre de lignes
# nb d'obs par source (atlas ou steli)
dat[ , .N, by = source]
# top 10 sp les plus obervées
dat[ , .N, by = scientificName][order(-N)][1:10]
```

## Extraire l'année depuis eventDate et compter par année

```{r}
# Création d’une nouvelle colonne
dat[ , year := year(eventDate)]  
# Nombre d'observations par année
dat[ , .N, by = year][order(year)]
```

## Observations par région

```{r}
dat[ , .N, by = region][order(-N)]
```

## Observations par famille de libellules

```{r}
dat[ , .N, by = family][order(-N)]
```

## Création d’un sous-ensemble (filtrage)

```{r}
# toutes les observations de l’espèce Calopteryx splendens
dat[scientificName == "Calopteryx splendens"]
# uniquement les observations après 2010
dat[year > 2010]
```

## 4 petits challenges

### trouver les 5 genres les plus fréquents

```{r}
dat[ , .N, by = genus][order(-N)][1:5]
```

### calculer le nb moy d'obs par commune

```{r}
# Compter le nombre d'observations par commune
obs_par_commune <- dat[, .N, by = municipality][order(-N)]
# Calculer la moyenne
moyenne <- mean(obs_par_commune$N)
# Afficher les résultats
obs_par_commune
moyenne
```

```{r}
ggplot(obs_par_commune, aes(x = N)) +
  geom_histogram(bins = 100) +
  scale_x_log10() +
  theme_minimal()
summary(obs_par_commune$N)
```

### trouver combien d'sp diff ont été obs dans chaque région

```{r}
dat[, .(n_species = uniqueN(scientificName)), by = region][order(-n_species)]
```

### trouver l'année avec le plus d'obs pour chaque source

```{r}
unique(dat$source)
dat.steli <- dat[source == "STELI"]
dat.steli[ , .N, by = year][order(-N)]
dat.atlas <- dat[source == "atlas"]
dat.atlas[ , .N, by = year][order(-N)]
```

```{r}
dat[, .N, by = .(source, year)][order(-N), .SD[1], by = source]
```

# (17/04) Exercices

## Librairies et préparation des données

```{r}
library(data.table)
library(here)
library(sf)
library(ggplot2)
library(rnaturalearth)

# Définir le chemin du fichier
read_folder <- here("data/03_grid")
# Charger les données dans un data.table
dat <- readRDS(file.path(read_folder, "french_odonate_data.rds"))
dat <- as.data.table(dat)
```
```{r}
# Je dois réduire la taille des données pour simplifier les exercices
## création d’une nouvelle colonne year
dat[ , year := year(eventDate)]
## filtrage du jeu de donnée
dat_2018 <- dat[year=="2018"]
```


## Cartes simples avec sf et rnaturalearth

### Représenter toutes les données

```{r}
# Convertir en sf
dat_sf <- st_as_sf(dat_2018, coords = c("x_ETRS89_LAEA", "y_ETRS89_LAEA"))
st_crs(dat_sf) <- 3035

# Carte de la France
fr <- ne_countries(scale = 50, country = "France", returnclass = "sf")
fr_3035 <- st_transform(fr, 3035)

# Obtenir la bounding box des données
bbox <- st_bbox(dat_sf)

# Créer la carte avec zoom automatique sur les données
ggplot() +
  geom_sf(data = fr_3035, fill = "gray95") +
  geom_sf(data = dat_sf, size = 0.1, alpha = 0.5, aes(color = source)) +
  coord_sf(xlim = c(bbox$xmin, bbox$xmax),
           ylim = c(bbox$ymin, bbox$ymax)) +
  theme_minimal()
```

### Représenter les données steli seulement

```{r}
## filtrage du jeu de donnée
dat_2018steli <- dat_2018[source=="STELI"]

# Convertir en sf
dat_sf <- st_as_sf(dat_2018steli, coords = c("x_ETRS89_LAEA", "y_ETRS89_LAEA"))
st_crs(dat_sf) <- 3035

# Carte de la France
fr <- ne_countries(scale = 50, country = "France", returnclass = "sf")
fr_3035 <- st_transform(fr, 3035)

# Obtenir la bounding box des données
bbox <- st_bbox(dat_sf)

# Créer la carte avec zoom automatique sur les données
ggplot() +
  geom_sf(data = fr_3035, fill = "gray95") +
  geom_sf(data = dat_sf, size = 0.1, alpha = 0.5, aes(color = source)) +
  coord_sf(xlim = c(bbox$xmin, bbox$xmax),
           ylim = c(bbox$ymin, bbox$ymax)) +
  theme_minimal()
```

### Représenter les données steli et atlas séparément pour comparer

```{r}
# Convertir en sf
dat_sf <- st_as_sf(dat_2018, coords = c("x_ETRS89_LAEA", "y_ETRS89_LAEA"))
st_crs(dat_sf) <- 3035

# Carte de la France
fr <- ne_countries(scale = 50, country = "France", returnclass = "sf")
fr_3035 <- st_transform(fr, 3035)

# Obtenir la bounding box des données
bbox <- st_bbox(dat_sf)

# Créer la carte avec zoom automatique sur les données et un facet_wrap
ggplot() +
  geom_sf(data = fr_3035, fill = "gray95") +
  geom_sf(data = dat_sf, size = 0.1, alpha = 0.5, aes(color = source)) +
  coord_sf(xlim = c(bbox$xmin, bbox$xmax),
           ylim = c(bbox$ymin, bbox$ymax)) +
  facet_wrap(facets = vars(source))
```

## Graphiques exploratoires avec ggplot2 : Evolution temporelle de la diversité

### Nombre d’observations par an

```{r}
dat[, year := year(eventDate)]

dat_year <- dat[, .N, by = .(year, source)]

ggplot(dat_year, aes(x = year, y = N, color = source)) +
  geom_line() +
  geom_point() +
  theme_minimal() +
  labs(title = "Évolution du nombre d’observations", y = "Nombre")
```

### Ajouter une courbe de tendance (geom_smooth)

```{r}
ggplot(dat_year, aes(x = year, y = N, color = source)) +
  geom_line() +
  geom_point() +
  geom_smooth(se = FALSE) +
  theme_minimal() +
  labs(title = "Évolution du nombre d’observations", y = "Nombre")
```

### Nombre d’espèces différentes par an

```{r}
dat[, year := year(eventDate)]

dat_year <- dat[, .(n_species = uniqueN(scientificName)), by = .(year, source)]

ggplot(dat_year, aes(x = year, y = n_species, color = source)) +
  geom_line() +
  geom_point() +
  theme_minimal() +
  labs(title = "Évolution du nombre d'espèces différentes", y = "Nombre")
```

### Ajouter une courbe de tendance (geom_smooth)

```{r}
ggplot(dat_year, aes(x = year, y = n_species, color = source)) +
  geom_line() +
  geom_point() +
  geom_smooth(se = FALSE) +
  theme_minimal()
```

# (18/04) Exercice poussé : Quelles sont les 3 régions avec la plus grande richesse spécifique moyenne par commune ? 

```{r}
# créer une table avec les communes et les régions
comm_reg <- dat[, .(municipality, region)]
# dans une autre table, compter le nombre d'espèces par commune
n_sp_comm <- dat[, .(n_species = uniqueN(scientificName)), by = municipality]
# joindre ces 2 tables par les communes, pour ajouter la région dans la table n_sp_comm
n_sp_comm_reg <- n_sp_comm[comm_reg, on = .(municipality)]
# calculer la moyenne communale par région
n_sp_comm_reg[, moy_comm := mean(n_species, na.rm = TRUE), by = region]
# agréger la table et afficher les 3 premières lignes
moy_sp_comm_by_region <- n_sp_comm_reg[, .(moy_comm = mean(n_species, na.rm = TRUE)), by = region]
moy_sp_comm_by_region[order(-moy_comm)]
```

J'obtiens la bonne solution mais je peux simplifier le code : 

```{r}
# compter le nombre d'espèces par commune tout en gardant la région dans la table 
n_sp_comm_reg <- dat[, .(n_species = uniqueN(scientificName)), by = .(municipality, region)]
# calculer la moyenne par commune, par région
moy_sp_comm_by_region <- n_sp_comm_reg[, .(moy_comm = mean(n_species, na.rm = TRUE)), by = region]
# afficher les 3 plus grandes moyennes régionales
moy_sp_comm_by_region[order(-moy_comm)][1:3]
```
Cette version est plus concise mais sous-estime de moitié les moyennes régionales, ça indique une incohérence quelque part, par exemple si certaines communes sont liées à plusieurs régions, à vérifier.

## Vérification du lien communes-régions dans les données (18/04)

```{r}
# Voir combien de communes sont associées à plus d'une région
communes_probleme <- dat[, .(n_regions = uniqueN(region)), by = municipality][n_regions > 1][order(municipality)]
nrow(communes_probleme)
DT::datatable(communes_probleme)
```

Je sélectionne APREMONT (Auvergne-Rhône-Alpes) pour voir les différentes régions auxquelles elle est rattachée dans les données.

```{r}
dat[municipality == "APREMONT", .N, by = region]
```

En effet, les noms de commune ne sont pas uniques en France, je vais donc répondre à la question de l'exercice (moyennes régionales ?) mais en me servant d'identifiants uniques (ex : id_10000) plutôt que les noms de commune.

## Exercice modifié : quelles sont les 3 régions avec la plus grande richesse spécifique moyenne par cellule de 10km² ?

Je vais refaire les 2 scripts pour vérifier si j'obtiens bien le même résultat cette fois-ci

```{r}
# créer une table avec les id et les régions
id_reg <- dat[, .(id_10000, region)]
# dans une autre table, compter le nombre d'espèces par id
n_sp_id <- dat[, .(n_species = uniqueN(scientificName)), by = id_10000]
# joindre ces 2 tables par les id, pour ajouter la région dans la table
n_sp_id_reg <- n_sp_id[id_reg, on = .(id_10000)]
# calculer la moyenne id par région
n_sp_id_reg[, moy_id := mean(n_species, na.rm = TRUE), by = region]
# agréger la table et afficher les 3 premières lignes
moy_sp_id_par_region <- n_sp_id_reg[, .(moy_id = mean(n_species, na.rm = TRUE)), by = region]
moy_sp_id_par_region[order(-moy_id)][1:3]
```

```{r}
# compter le nombre d'espèces par id tout en gardant la région dans la table 
n_sp_id_reg <- dat[, .(n_species = uniqueN(scientificName)), by = .(id_10000, region)]
# calculer la moyenne par id, par région
moy_sp_id_par_region <- n_sp_id_reg[, .(moy_id = mean(n_species, na.rm = TRUE)), by = region]
# afficher les 3 plus grandes moyennes régionales
moy_sp_id_par_region[order(-moy_id)][1:3]
```

Je n'obtiens pas le même résultat, pourquoi ?
En fait c'est probablement le même problème mais pour d'autres raisons, la grille 10km² ne suit pas les limites régionales donc certaines cellules doivent probablement être rattachées à plusieurs régions, ce qui crée encore une fois des incohérences selon la manière de calculer.

Bref si je veux faire des richesses spécifiques moyennes régionales je sais pas trop quelle est la meilleure méthode au final...

